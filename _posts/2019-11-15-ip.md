---
title: "From Paint to PhotoShop real quick: Generating photo-realistic images using semantic image synthesis"
date: 2019-11-03
tags: [image processing, artificial intelligence, deep learning]
header:
  image: "/images/rally/title.png"
  teaser: "/images/animation/time_series.gif"
excerpt: "Style transfer and realistic image rendering using Neural Networks."
mathjax: true

---
<div id="fb-root"></div>
<script async defer src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&version=v3.2"></script>

Have you heard the latest buzz from NVDIA? Their engineers where able to create an algorithm that converts semantic images, the ones that you doodle in MS Paint as a toddler, to very realistic images.

Just look at this animation:

{:refdef: style="text-align: center;"}
<img src="{{ site.url }}{{ site.baseurl }}/images/ip/gaugan.gif" alt="Gaugan." class="center">
{: refdef}

I was not born with artistically coordinated hands. I can’t even draw passable stick figures. My right hand sketches are practically as bad as my left. Having a physics background only worsened this ‘skill’ as I was trained to assume and over simplify 3D moving objects as 1D dots and particles connected with hasty crooked arrows. I find art fun but I guess it’s not mutual.

Now, with the advent of deep learning and machine learning in image processing, we can all be the Van Goghs and Picassos that we dreamed of.

To start, here is a [link](https://arxiv.org/abs/1903.07291) of their paper if you don't want any spoilers.

This a very technical paper and the state-of-the-art in image segmentation and style transfer.

Want to collaborate? Message me in [LinkedIn](https://ph.linkedin.com/in/albertyumol).

<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6410209740119334",
    enable_page_level_ads: true
  });
</script>

<div class="fb-comments" data-href="https://albertyumol.github.io/" data-numposts="5"></div>
