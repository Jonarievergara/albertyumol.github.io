---
title: "Class Demo: Scraping your Facebook posts with BeautifulSoup"
date: 2020-05-20
tags: [data mining, data science, webscraping]
header:
  image: "/images/rally/title.png"
  teaser: "/images/animation/time_series.gif"
excerpt: "Data Science is not only about fancy algorithms, statistics and math. It is also about credibly sourcing your data. Given that the bulk of data is in the internet hiding in the backend or scattered in the frontend of websites, web scraping is indeed a handy technique. "
mathjax: true

---
<div id="fb-root"></div>
<script async defer src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&version=v3.2"></script>

It has been a while since my last post. The corona crisis really altered my schedule and plans for 2020. But we need to adapt, move forward and proceed to our new normal. I am lucky right now that I am able to write again, be able to breathe freely.

To the reader, sending you virtual hugs. I know that we are in rough times, but this too shall pass.

This post is a demonstration I used in my Web Scraping class for Eskwelabs. The goal is to scrape facebook posts (your own) and make a `Word Cloud` from it.

Data Science is not only about fancy algorithms, statistics and math. It is also about credibly and creatively sourcing your data. Given that the bulk of data is in the internet hiding in the backend or scattered in the frontend of websites, ethical web scraping (also called as data mining/web crawling) is indeed a handy technique.

The [Cambridge Analytica Scandal](https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal) took its toll and changed the data mining landscape giving focus to data ownership and privacy. Personal data of millions of Facebook users where scraped and used without consent for political advertising and campaigns.

It was a good thing that in 2018, the European Union pushed through implementing the General Data Protection Regulation (GDPR) that put privacy of people with their digital data at a premium.

Because of this a lot of tech companies mandated that their users will have the option to download their personal data (although it is unclear if these data is complete). At the very least we have a sense of ownership and visibility to our own data. If ever Facebook sells my info at least I know what info they got from me. And maybe think of how they might use this data. Let's start scraping!

### Step 1: Download Facebook Data
Log-in to your facebook account. Go to settings and click download your information.

{:refdef: style="text-align: center;"}
<img src="{{ site.url }}{{ site.baseurl }}/images/fb/fb_1.png" alt="download_info" class="center">
{: refdef}

For the purposes of this tutorial/demo, we are only interested in your posts. So untick all check boxes except for posts.

{:refdef: style="text-align: center;"}
<img src="{{ site.url }}{{ site.baseurl }}/images/fb/fb_2.png" alt="posts" class="center">
{: refdef}

Here are the recommended filters:
- Date Range: All of my data
- Format: HTML
- Media Quality: Low (for faster download, we are interested to just texts anyway)

Click create file. You will be notified when it is ready to download. You will be prompted to download a zip file. Download and unzip it.

Open the unzipped folder, find the `posts` folder and locate the `your_posts_1.html` file.

{:refdef: style="text-align: center;"}
<img src="{{ site.url }}{{ site.baseurl }}/images/fb/fb_3.png" alt="posts_html" class="center">
{: refdef}

Now let's do us some Python üòÅ

You need to install [BeautifulSoup](https://anaconda.org/anaconda/beautifulsoup4) and [WordCloud](https://anaconda.org/conda-forge/wordcloud)

We now use beautiful soup to make a hot fudge of html mess.

<script src="https://gist.github.com/albertyumol/896ddf060e98727b4f7b46f745a1fa49"></script>

To get the text of posts that I posted, let us check first the source code using my favorite browser's (MOZILLA FIREFOX) inspector. Right click on a post and click inspect element (or whatever counterpart you have with your browser but I say switch to FIREFOX, the most [secure browser](https://www.zdnet.com/article/germanys-cyber-security-agency-recommends-firefox-as-most-secure-browser/)).

{:refdef: style="text-align: center;"}
<img src="{{ site.url }}{{ site.baseurl }}/images/fb/fb_4.png" alt="inspect" class="center">
{: refdef}

Navigate along and do some pattern recognition to identify the correct class to filter. My guess would be `_2pin`.

{:refdef: style="text-align: center;"}
<img src="{{ site.url }}{{ site.baseurl }}/images/fb/fb_5.png" alt="filter" class="center">
{: refdef}

So let's find all the div's and filter all classes in `_2pin`. Checking the contents, we are correct that `_2pin` captures all of the posts. The following code demonstrates how it's done. I made a list `x` to contain all of the posts.

<script src="https://gist.github.com/albertyumol/51b3ee04d9d0902299f1d7c253efc421.js"></script>

We concatenate the list into one string then we visualize the words using Word Cloud.

<script src="https://gist.github.com/albertyumol/ebc8f3716ebf97339b7edfeebe4b3a06.js"></script>

You will notice that there are some words that are not really relevant like https, PM. We technically call them `stop words` in Natural Language Processing (NLP).

We remove them,

<script src="https://gist.github.com/albertyumol/25d490c0c1577de95a6979e2e6daa1f3.js"></script>

And here is our final output:

{:refdef: style="text-align: center;"}
<img src="{{ site.url }}{{ site.baseurl }}/images/fb/fb_6.png" alt="output" class="center">
{: refdef}

In summary, we did a quick demonstration on how to download your data from Facebook, use BeautifulSoup to parse it, and create a wordcloud from scraped text. Scraping can be expanded to many applications in business and industry problems e.g. for data augmentation in competition and market research. Stay tuned for more tutorials on web scraoing, next would be scraping from APIs.



References:

+ [Social Data](http://socialdata.site/chapter_04/)


Questions? Contact me via [LinkedIn](https://ph.linkedin.com/in/albertyumol). I'm also on GitHub with the username [albertyumol](https://github.com/albertyumol).

<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6410209740119334",
    enable_page_level_ads: true
  });
</script>

<div class="fb-comments" data-href="https://albertyumol.github.io/" data-numposts="5"></div>
